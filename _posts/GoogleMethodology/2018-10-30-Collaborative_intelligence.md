---
layout: post
title: Collaborative_intelligence
date: 2018-10-30
tag: GoogleMethodology
site: https://zhangkn.github.io
catalog: true
author: kunnan
subtitle: 合作智能
---



# **1. 目前人工智能是设计者的智能。**



谁设计了人工智能的程序，谁就赋予了机器智能。在这种情况下，哪一家的人工智能更强，只取决于两个要素：

a）它的设计者的智能水平；

b）它使用的硬件的水平和数据量的多寡。





库旦普教授将约翰∙霍普金斯大学人工智能的研究定位在Google、微软等大公司研究机构有兴趣却不值得做的课题，具体讲就是更深入、更前瞻、短期未必见效的项目。事实上，Google、Facebook等公司也和它的中心有战略合作，寄希望于大学做更长远的研究。



`至于小公司，包括非IT的公司，库旦普教授认为，它们的出路就是利用大学和大公司的研究成果解决实际问题，具体说就是搞开发不要搞研究。这当然对初创公司和小公司有些残忍，但这是今天的现实。`





# 2. 今天的人工智能其实是昨天世界的某种再现，只不过从昨天到今天的变化是连续性的。





库旦普教授讲，由于人工智能技术主要依靠数据和所谓的智能算法，即数学模型。因此，它其实是再现昨天的世界，只不过昨天的世界和今天的世界之间是连续变化的。

* 比如说，人脸识别软件，使用你过去的照片进行训练，识别今天的你，之所以能识别得准，是因为昨天的你，去年的你，甚至10年前的你，和今天的你之间是渐变的、连续变化的，而不是跳变的。

* 再比如在语音识别中，一个人一辈子的发音，很多人对同一个语音的发音，都是相对稳定的。如果遇到不连续的情况，人工智能就失灵了。比如Google的无人驾驶汽车，遇到路上的沙袋就不认识了，这就是非连续性变化，它就要躲闪，而不是压过去，结果就撞了旁边的车。

* 每次到了金融危机时，由于次次情况都不太相同，因此交易股票的程序总要出错，触发股灾。而人的特点是，人们可以处理不连续性，因为他们不是重现昨天的世界。比如陪审团遇到过去没见过的案子，照样能够根据经验和常识作出较为合理的判断，一个人在荒野里没有了手机信号，没有了汽油，一样能想办法自救，而不需要经历第二次才学会处理。


# **3. 今天的人工智能是交互但是没有合作。**



在今天的人工智能应用中，计算机和人的交互从事先设定好，进步为按照事先设定的学习程序学习。

* 比如Google搜索就是一种交互，结果固然是事先的算法设定好的，但是当你开始对输出的结果提供反馈后，比如点击结果或者翻到下页之后，它就进行学习了，下一次的交互结果会不同。
* 再进一步，当你坐在无人驾驶汽车中，这辆汽车就会进行双重交互，一方面是和你（乘客）通过语音进行交互，另一方面是和其他车辆进行交互，比如躲避、超车、减速等等。



但是，到目前为止，所有的人工智能还只有交互。即使我们觉得它很贴心，也不过是因为机器学习，使得交互做得更好了，它还远没有开始和人进行合作，这一点和人不同。



* 还是拿自动驾驶为例。库旦普教授讲，Google的无人驾驶汽车比特斯拉的好得多，因为前者几乎不可能自己撞到隔离墩上，或者开出车道，而后者如果人不监控，会经常如此。但是库旦普教授说，这只是和环境交互得好，Google的无人驾驶汽车，依然无法和周围有人驾驶的汽车合作。今天，它几乎全部的交通事故（虽然大多是被动的），都源于它对周围司机行为的误判，比如速度过缓。
* 人在开车的时候，如果堵了后面的车，会主动躲到旁边（pull over），这就是一种合作。在遇到红绿灯时，会根据后面车子的速度决定是快速过去，还是停下来，以最安全的原则为准。这些常常是人之间的默契。但是今天的无人驾驶汽车是没有的。合作这件事，不是事先程序能够设计好的，甚至不是简单的机器学习能办到的。



# **4. 今天的人工智能，会放大个人意志。**





由于人工智能从本质上讲是设计者意志的体现，它越强大，其实就是将个人意志放得越大。以Facebook为例，它在美国中期选举前删了很多自认为不好的帖子，并且关掉了一些公众号。但是，大家质疑它，你凭什么删？Facebook讲，那些帖子是政治谩骂、恶意攻击。就算Facebook的判断没有错误，但是Facebook不是执法者，它没有权利执法。



* 造成这个结果的原因，库旦普教授认为，是因为我们作为用户，无法和Facebook的人工智能程序合作。最后，个人（人工智能的设计者）可以随意放大自己的意志。



# **5. 对于人工智能的未来，库旦普教授认为最关键的是建立与人合作的人工智能。**



他认为，今天的人工智能其实并不和使用者合作，它只是设计者意图的表现，设计者要想和你合作，你就觉得它显现出合作的特点。反之当设计者想利用它占你的便宜，你也无能为力。

但是，人做事不是这样，一个独裁者给下面的人下命令去害人，下面的人未必会遵从，因为`人和人之间是趋于合作，而不是对抗的`。

今后人工智能必须解决的三个问题是：与人的合作，隐私和数据安全问题，以及对非连续性情况的处理。





# See Also 

>* newpost 
>
```
/Users/devzkn/bin//newpost Collaborative_intelligence 合作智能 -t GoogleMethodology
> #原来""的参数，需要自己加上""
```

